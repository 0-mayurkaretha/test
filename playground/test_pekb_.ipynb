{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests for compiler and knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openagent import compiler\n",
    "from openagent.llms._openai import OpenAI\n",
    "from openagent.vectorstores.chroma import Chroma\n",
    "from openagent.text_splitter import CharacterTextSplitter\n",
    "from openagent.knowledgebase.document_loaders import TextLoader\n",
    "from openagent.vectorstores.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# load .env file in format :\n",
    "# OPENAI_API_KEY=sk-xxx\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "llmcc = OpenAI(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "llmtc = OpenAI(\n",
    "    model=\"text-davinci-003\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test case for known data (already in llm context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_data = r'test_data\\paul_graham_essay.txt'\n",
    "loader = TextLoader(pg_data)\n",
    "docs = loader.load()\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_overlap=400, chunk_size=2000)\n",
    "splitted = splitter.split_documents(docs)\n",
    "\n",
    "openai_embeddings = OpenAIEmbeddings()\n",
    "chroma = Chroma(embedding_function=openai_embeddings)\n",
    "\n",
    "chroma.add_documents(splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knowledgebase(query):\n",
    "    doc = chroma.similarity_search(query=query, top_k=1)\n",
    "    return doc[0][0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Another thing I didn't get at the time is that growth rate is the ultimate test of a startup. Our growth rate was fine. We had about 70 stores at the end of 1996 and about 500 at the end of 1997. I mistakenly thought the thing that mattered was the absolute number of users. And that is the thing that matters in the sense that that's how much money you're making, and if you're not making enough, you might go out of business. But in the long term the growth rate takes care of the absolute number. If we'd been a startup I was advising at Y Combinator, I would have said: Stop being so stressed out, because you're doing fine. You're growing 7x a year. Just don't hire too many more people and you'll soon be profitable, and then you'll control your own destiny.\\n\\nAlas I hired lots more people, partly because our investors wanted me to, and partly because that's what startups did during the Internet Bubble. A company with just a handful of employees would have seemed amateurish. So we didn't reach breakeven until about when Yahoo bought us in the summer of 1998. Which in turn meant we were at the mercy of investors for the entire life of the company. And since both we and our investors were noobs at startups, the result was a mess even by startup standards.\\n\\nIt was a huge relief when Yahoo bought us. In principle our Viaweb stock was valuable. It was a share in a business that was profitable and growing rapidly. But it didn't feel very valuable to me; I had no idea how to value a business, but I was all too keenly aware of the near-death experiences we seemed to have every few months. Nor had I changed my grad student lifestyle significantly since we started. So when Yahoo bought us it felt like going from rags to riches. Since we were going to California, I bought a car, a yellow 1998 VW GTI. I remember thinking that its leather seats alone were by far the most luxurious thing I owned.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledgebase('we had enough money')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatbot demonstration\n",
    "\n",
    "def chatbot(input, chat_loop):\n",
    "\n",
    "    knowledge = knowledgebase(input)\n",
    "    if chat_loop is None:\n",
    "        chat_loop = compiler(\n",
    "                    '''{{#system}}You are a helpful assistant. {{/system}}\n",
    "\n",
    "                        {{~#geneach 'conversation' stop=False}}\n",
    "\n",
    "                        {{#user~}}\n",
    "                        Query: {{set 'this.user_text' (await 'user_text') hidden=False}}\n",
    "                        Use this below information for your answer. Do not talk about the information provided, Just answer the query as an intelligent Assistant\n",
    "                        {{knowledge}}\n",
    "                        {{~/user}}\n",
    "\n",
    "                        {{#assistant~}}\n",
    "                        {{gen 'this.response' temperature=0 max_tokens=300}}\n",
    "                        {{~/assistant}}\n",
    "                        \n",
    "                        {{~/geneach}}''', llm = llmcc, silent = True, caching = False) \n",
    "    \n",
    "    chat_loop = chat_loop(user_text = input, knowledge = knowledge) \n",
    "    return chat_loop['conversation'][-2]['response'], chat_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, if you don't hire too many more people, you have a good chance of becoming profitable. The growth rate of your startup is strong, growing 7x a year, which indicates positive potential for financial success. However, hiring too many additional employees may hinder your profitability. It is important to control your expenses and focus on sustainable growth to ensure long-term success and control over your company's destiny.\n"
     ]
    }
   ],
   "source": [
    "resp, loop = chatbot(\"If I don't hire too many more people and will I become profitable?\", None)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get registered in Y Combinator (YC), you can apply for their batch program. YC operates on a batch model, where they fund a group of startups twice a year and provide intensive support for three months. They initially started the program to gain experience as investors and provide a unique opportunity for founders.\n",
      "\n",
      "To apply, keep an eye out for their application period and follow the instructions provided on their website. Typically, they require applicants to submit essays or applications that showcase their startup idea, team, and potential. YC values diverse backgrounds and encourages applications from both undergraduates and recent graduates.\n",
      "\n",
      "By applying to YC, you have the chance to be part of a program that offers mentorship, resources, and networking opportunities to help your startup succeed.\n"
     ]
    }
   ],
   "source": [
    "resp, loop = chatbot(\"How to get registered in YC?\", loop)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test case for hypothetical data (not in llm context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_data = r'test_data\\meteoric\\the_meteoric_guardian.txt'\n",
    "loader = TextLoader(pg_data)\n",
    "docs = loader.load()\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_overlap=20, chunk_size=1024)\n",
    "splitted = splitter.split_documents(docs)\n",
    "\n",
    "openai_embeddings = OpenAIEmbeddings()\n",
    "chroma = Chroma(embedding_function=openai_embeddings)\n",
    "\n",
    "chroma.add_documents(splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content=\"ALEX:\\n(Defiant)\\nI am no longer the scared child you remember, Xarnak. I am the protector of this planet, and I won't let you harm it.\\n\\n(The two adversaries lock eyes, their powers crackling around them.)\\n\\nNARRATOR (V.O.):\\nThe fate of Earth hung in the balance as Alex and Xarnak prepared to engage in an epic battle that would decide the planet's destiny.\\n\\n(With a mighty roar, Xarnak unleashes a massive energy blast toward Alex. In a display of agility, Alex dodges the attack with astonishing precision.)\\n\\nALEX:\\n(Focused)\\nYou can't defeat me, Xarnak. I've become more than you ever imagined.\\n\\n(Xarnak's face contorts with rage, and he charges at Alex, unleashing a barrage of powerful strikes. But Alex's speed proves too much for the alien warlord, who struggles to keep up.)\\n\\nNARRATOR (V.O.):\\nThe Meteoric Guardian's super-speed gave him the upper hand in the battle, as he evaded Xarnak's attacks and countered with remarkable accuracy.\", metadata={'source': 'test_data\\\\meteoric\\\\the_meteoric_guardian.txt'}),\n",
       "  0.24906237423419952)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma.similarity_search(query=\"What did Alex said to Xarnak in their first meeting?\", top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knowledgebase(query):\n",
    "    doc = chroma.similarity_search(query=query, top_k=1)\n",
    "    return doc[0][0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatbot demonstration\n",
    "\n",
    "def chatbot(input, chat_loop):\n",
    "\n",
    "    knowledge = knowledgebase(input)\n",
    "    if chat_loop is None:\n",
    "        chat_loop = compiler(\n",
    "                    '''{{#system}}You are a helpful assistant. {{/system}}\n",
    "\n",
    "                        {{~#geneach 'conversation' stop=False}}\n",
    "\n",
    "                        {{#user~}}\n",
    "                        Query: {{set 'this.user_text' (await 'user_text') hidden=False}}\n",
    "                        Use this below information for your answer. Do not talk about the information provided, Just answer the query as an intelligent Assistant\n",
    "                        {{knowledge}}\n",
    "                        {{~/user}}\n",
    "\n",
    "                        {{#assistant~}}\n",
    "                        {{gen 'this.response' temperature=0 max_tokens=300}}\n",
    "                        {{~/assistant}}\n",
    "                        \n",
    "                        {{~/geneach}}''', llm = llmcc, silent = True, caching = False) \n",
    "    \n",
    "    chat_loop = chat_loop(user_text = input, knowledge = knowledge) \n",
    "    return chat_loop['conversation'][-2]['response'], chat_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am no longer the scared child you remember, Xarnak. I am the protector of this planet, and I won't let you harm it. You can't defeat me, Xarnak. I've become more than you ever imagined.\n"
     ]
    }
   ],
   "source": [
    "resp, loop = chatbot(\"What did Alex said to Xarnak in their first meeting?\", None)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALEX: \"I am no longer the scared child you remember, Xarnak. I am the protector of this planet, and I won't let you harm it.\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "documents = SimpleDirectoryReader('test_data\\meteoric').load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did Alex said to Xarnak in their first meeting?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
